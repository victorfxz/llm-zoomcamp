{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb173625-ed3f-4df2-aed3-406949872541",
   "metadata": {},
   "source": [
    "## Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280b5ca4-f2ba-4e5a-b797-838190fec1e5",
   "metadata": {},
   "source": [
    "### Question 1. Mage version "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78b2e0f-b97b-4fe3-b75f-eb2babcc4197",
   "metadata": {},
   "source": [
    "Mage version is **0.9.72**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959a1a08-be26-44a9-b328-7d6645e8f138",
   "metadata": {},
   "source": [
    "### Question 2. Number of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d10d78f1-5462-4219-a89a-e07980ba522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "import docx\n",
    "\n",
    "def clean_line(line):\n",
    "    line = line.strip()\n",
    "    line = line.strip('\\uFEFF')\n",
    "    return line\n",
    "\n",
    "def read_faq(file_id):\n",
    "    url = f'https://docs.google.com/document/d/{file_id}/export?format=docx'\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    with io.BytesIO(response.content) as f_in:\n",
    "        doc = docx.Document(f_in)\n",
    "\n",
    "    questions = []\n",
    "\n",
    "    question_heading_style = 'heading 2'\n",
    "    section_heading_style = 'heading 1'\n",
    "    \n",
    "    heading_id = ''\n",
    "    section_title = ''\n",
    "    question_title = ''\n",
    "    answer_text_so_far = ''\n",
    "     \n",
    "    for p in doc.paragraphs:\n",
    "        style = p.style.name.lower()\n",
    "        p_text = clean_line(p.text)\n",
    "    \n",
    "        if len(p_text) == 0:\n",
    "            continue\n",
    "    \n",
    "        if style == section_heading_style:\n",
    "            section_title = p_text\n",
    "            continue\n",
    "    \n",
    "        if style == question_heading_style:\n",
    "            answer_text_so_far = answer_text_so_far.strip()\n",
    "            if answer_text_so_far != '' and section_title != '' and question_title != '':\n",
    "                questions.append({\n",
    "                    'text': answer_text_so_far,\n",
    "                    'section': section_title,\n",
    "                    'question': question_title,\n",
    "                })\n",
    "                answer_text_so_far = ''\n",
    "    \n",
    "            question_title = p_text\n",
    "            continue\n",
    "        \n",
    "        answer_text_so_far += '\\n' + p_text\n",
    "    \n",
    "    answer_text_so_far = answer_text_so_far.strip()\n",
    "    if answer_text_so_far != '' and section_title != '' and question_title != '':\n",
    "        questions.append({\n",
    "            'text': answer_text_so_far,\n",
    "            'section': section_title,\n",
    "            'question': question_title,\n",
    "        })\n",
    "\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4f7ca82-1f1e-41dc-8ee3-dd10e4f08973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm-zoomcamp\n",
      "\n",
      "Number of FAQ documents processed: 1\n"
     ]
    }
   ],
   "source": [
    "faq_documents = {\n",
    "    'llm-zoomcamp': '1qZjwHkvP0lXHiE4zdbWyUXSVfmVGzougDD6N37bat3E',\n",
    "}\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course, file_id in faq_documents.items():\n",
    "    print(course)\n",
    "    course_documents = read_faq(file_id)\n",
    "    documents.append({'course': course, 'documents': course_documents})\n",
    "\n",
    "print(f\"\\nNumber of FAQ documents processed: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9a5277-0e65-4416-b5fc-bcd3e3cc4675",
   "metadata": {},
   "source": [
    "### Question 3. Chunking: number of questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42a9e777-fcc3-426c-8b9b-7b4b25aee690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def generate_document_id(doc):\n",
    "    combined = f\"{doc['course']}-{doc['question']}-{doc['text'][:10]}\"\n",
    "    hash_object = hashlib.md5(combined.encode())\n",
    "    hash_hex = hash_object.hexdigest()\n",
    "    document_id = hash_hex[:8]\n",
    "    return document_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fb3288c-8120-4d4b-8b9b-93ab1682e236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents (chunks): 86\n"
     ]
    }
   ],
   "source": [
    "data = documents[0]\n",
    "documents = []\n",
    "\n",
    "for doc in data['documents']:\n",
    "    doc['course'] = data['course']\n",
    "    doc['document_id'] = generate_document_id(doc)\n",
    "    documents.append(doc)\n",
    "\n",
    "print(f\"Number of documents (chunks): {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebbdef8-4533-4a23-8450-41a2ff2ffd70",
   "metadata": {},
   "source": [
    "### Question 4. Export: last processed document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a0c2ad1-b0d7-4e3e-becf-45862b4cc3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from elasticsearch import Elasticsearch\n",
    "import hashlib\n",
    "\n",
    "def clean_line(line):\n",
    "    return line.strip().strip('\\uFEFF')\n",
    "\n",
    "def read_faq(file_id):\n",
    "    url = f'https://docs.google.com/document/d/{file_id}/export?format=docx'\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    with io.BytesIO(response.content) as f_in:\n",
    "        doc = docx.Document(f_in)\n",
    "\n",
    "    questions = []\n",
    "    question_heading_style = 'heading 2'\n",
    "    section_heading_style = 'heading 1'\n",
    "    \n",
    "    section_title = ''\n",
    "    question_title = ''\n",
    "    answer_text_so_far = ''\n",
    "     \n",
    "    for p in doc.paragraphs:\n",
    "        style = p.style.name.lower()\n",
    "        p_text = clean_line(p.text)\n",
    "    \n",
    "        if len(p_text) == 0:\n",
    "            continue\n",
    "    \n",
    "        if style == section_heading_style:\n",
    "            section_title = p_text\n",
    "            continue\n",
    "    \n",
    "        if style == question_heading_style:\n",
    "            answer_text_so_far = answer_text_so_far.strip()\n",
    "            if answer_text_so_far != '' and section_title != '' and question_title != '':\n",
    "                questions.append({\n",
    "                    'text': answer_text_so_far,\n",
    "                    'section': section_title,\n",
    "                    'question': question_title,\n",
    "                })\n",
    "                answer_text_so_far = ''\n",
    "    \n",
    "            question_title = p_text\n",
    "            continue\n",
    "        \n",
    "        answer_text_so_far += '\\n' + p_text\n",
    "    \n",
    "    answer_text_so_far = answer_text_so_far.strip()\n",
    "    if answer_text_so_far != '' and section_title != '' and question_title != '':\n",
    "        questions.append({\n",
    "            'text': answer_text_so_far,\n",
    "            'section': section_title,\n",
    "            'question': question_title,\n",
    "        })\n",
    "\n",
    "    return questions\n",
    "\n",
    "def generate_document_id(doc):\n",
    "    combined = f\"{doc['course']}-{doc['question']}-{doc['text'][:10]}\"\n",
    "    hash_object = hashlib.md5(combined.encode())\n",
    "    hash_hex = hash_object.hexdigest()\n",
    "    return hash_hex[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36bd2a88-2e5b-4df8-8fb3-e4ebfc3b0e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(['http://localhost:9200'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26d0aaa3-d7a5-4e20-b9a1-50ef861b46a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index name: documents_20240816_202103\n"
     ]
    }
   ],
   "source": [
    "index_name_prefix = 'documents'\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "index_name = f\"{index_name_prefix}_{current_time}\"\n",
    "print(\"index name:\", index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a648c2a-281b-42e7-bce0-83e9571b47d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"document_id\": {\"type\": \"keyword\"}\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed427447-7821-4e56-a662-d737f51d4d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.indices.create(index=index_name, body=index_settings)\n",
    "\n",
    "faq_documents = {\n",
    "    'llm-zoomcamp': '1qZjwHkvP0lXHiE4zdbWyUXSVfmVGzougDD6N37bat3E'\n",
    "}\n",
    "\n",
    "documents = []\n",
    "for course, file_id in faq_documents.items():\n",
    "    course_documents = read_faq(file_id)\n",
    "    documents.append({'course': course, 'documents': course_documents})\n",
    "\n",
    "last_document = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcc823a4-0634-4d63-8b0c-e7060487b0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last document: {'text': 'Answer', 'section': 'Workshops: X', 'question': 'Question', 'course': 'llm-zoomcamp', 'document_id': 'd8c4c7bb'}\n"
     ]
    }
   ],
   "source": [
    "for course_dict in documents:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        doc['document_id'] = generate_document_id(doc)\n",
    "        es.index(index=index_name, id=doc['document_id'], body=doc)\n",
    "        last_document = doc\n",
    "\n",
    "print(f\"Last document: {last_document}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e6084b-2e70-4e92-9f6f-05dffa09806a",
   "metadata": {},
   "source": [
    "### Question 5. Testing the retrieval: document id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73eb2e46-4c9d-46e3-8a25-e8713a97791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"When is the next cohort?\"\n",
    "\n",
    "query = {\n",
    "    \"size\": 10,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": user_question,\n",
    "                    \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "078bb83c-a6ec-4153-9e34-da8204affdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section: General course-related questions\n",
      "ID: bf024675\n",
      "Question: When will the course be offered next?\n",
      "Score: 25.331835\n",
      "\n",
      "Section: Module 3: X\n",
      "ID: ee355823\n",
      "Question: What is the cosine similarity?\n",
      "Score: 12.660435\n",
      "\n",
      "Section: Workshops: dlthub\n",
      "ID: 6cf805ca\n",
      "Question: There is an error when opening the table using dbtable = db.open_table(\"notion_pages___homework\"): FileNotFoundError: Table notion_pages___homework does not exist.Please first call db.create_table(notion_pages___homework, data)\n",
      "Score: 12.212482\n",
      "\n",
      "Section: Workshops: dlthub\n",
      "ID: e18124d4\n",
      "Question: There is an error when running main(): FileNotFoundError: Table notion_pages___homework does not exist.Please first call db.create_table(notion_pages___homework, data)\n",
      "Score: 11.193924\n",
      "\n",
      "Section: General course-related questions\n",
      "ID: fb81c6ff\n",
      "Question: I was working on next week’s homework/content - why does it keep changing?\n",
      "Score: 10.403244\n",
      "\n",
      "Section: General course-related questions\n",
      "ID: a5301a1f\n",
      "Question: What is the video/zoom link to the stream for the “Office Hours” or live/workshop sessions?\n",
      "Score: 10.195723\n",
      "\n",
      "Section: Module 1: Introduction\n",
      "ID: baea0a66\n",
      "Question: Authentication: Why is my OPENAI_API_KEY not found in the jupyter notebook?\n",
      "Score: 10.018553\n",
      "\n",
      "Section: General course-related questions\n",
      "ID: a57f9581\n",
      "Question: Course - I have registered for the [insert-zoomcamp-name]. When can I expect to receive the confirmation email?\n",
      "Score: 9.809071\n",
      "\n",
      "Section: Module 3: X\n",
      "ID: 2806a1c1\n",
      "Question: TypeError: unsupported operand type(s) for *: 'float' and 'dict' when running the vector search function within the evaluate function\n",
      "Score: 9.571264\n",
      "\n",
      "Section: Module 4: Monitoring\n",
      "ID: a2dca2e2\n",
      "Question: OperationalError when running python prep.pypsycopg2. OperationalError: could not translate host name \"postgres\" to address: No such host is known. How do I fix this issue?\n",
      "Score: 9.361139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index_name = 'documents_20240816_202103'\n",
    "response = es.search(index = index_name, body = query)\n",
    "\n",
    "for hit in response['hits']['hits']:\n",
    "    doc = hit['_source']\n",
    "    print(f\"Section: {doc['section']}\")\n",
    "    print(f\"ID: {doc['document_id']}\")\n",
    "    print(f\"Question: {doc['question']}\")\n",
    "    print(f\"Score: {hit['_score']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
